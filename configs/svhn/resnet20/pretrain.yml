dataset:
  transform: augment

criterion:
  name: ce
  perm_loss_rho: 0.0001
  perm_loss_rho_gamma: 1.07
  area_loss_rho: 0.1
  cross_density_loss_rho: 0.1

aux_criterion:
  kl_distill:
    weight: 0

optimizer:
  name: sgd
  lr: 0.02
  weight_decay: 0.0001
  momentum: 0.9

scheduler:
  name: cosine
  lr_gamma: 0.99
  lr_min: 1e-5
  warmup_steps: 0

run:
  experiment: "svhn_resnet20_pretrain"
  n_epochs: 100
  batch_size: 64
  use_cuda: 1
  gpu_id: 0
  deterministic: 1
  random_state: 42
  log_interval: 200
  train_noise: 0
  inplace_distill: False
  train_arch_epoch: 10
  train_arch_interval: 4
  train_arch_ratio: 0.2
  force_perm_legal_epoch: 70
  do_distill: False
  grad_clip: True
  max_grad_value: 1

quantize:
  weight_bit: 32
  input_bit: 32
  v_pi: 4.36
  v_max: 2.0

noise:
  input_snr: 0
  input_er: 0
  detection_noise: 0
  detection_snr: 0
  sigma_noise_std: 0
  phase_noise_std: 0
  dc_noise_std: 0
  cr_noise_std: 0

device:
  coupler_transmission_factor_t: 0.711
  coupler_insertion_loss: 0.045
  crossing_transmission_factor: 0.983
  crossing_phase_shift: 0.08
  phase_noise_std: 0
  input_uncertainty: 0

checkpoint:
  save_best_model_k: 3
  checkpoint_dir: "svhn/resnet20/pretrain"
  model_comment: ""
  resume: 0
  restore_checkpoint: ""
  no_linear: 0

model:
  name: "ResNet20"
  kernel_list: [6, 16]
  kernel_size_list: [5, 5]
  stride_list: [1, 1]
  padding_list: [2, 0]
  hidden_list: [120, 84]
  block_list: [16, 16, 16, 16, 16]
  pool_out_size: 0
  act: relu
  act_thres: 6
  norm: bn
  photodetect: True
  bn_affine: True

super_layer:
  name: ps_dc_cr_adeptzero
  arch:
    n_waveguides: 16
    n_front_share_waveguides: 16
    n_front_share_ops: 16
    n_blocks: 16
    n_layers_per_block: 2
    n_front_share_blocks: 2
    share_ps: none
    interleave_dc: True
    symmetry_cr: False
    cr_layer_init_alg: noisy_identity
    device_cost:
      ps_weight: 1
      dc_weight: 1
      cr_weight: 1
      area_upper_bound: 100
      area_lower_bound: 80
      first_active_block: False
  sample_arch: [2, 1, 2, 1, 2, 1, 2, 1, 4]
  sampler:
    strategy:
      name: plain # plain, limit_diff
  num_subnet_training: 3
  init_gumbel_temperature: 5
  gumbel_decay_rate: 0.956
  arch_mask_mode: gumbel_soft


teacher:
  name: null
  checkpoint: ""

debug:
  verbose: 1

